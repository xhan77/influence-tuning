{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import csv\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_file = '../resources/msgs/main_verb_absolute_token_position/train.jsonl'\n",
    "# test_file = '../resources/msgs/main_verb_absolute_token_position/test.jsonl'\n",
    "# inoc_file = '../resources/msgs/main_verb_absolute_token_position/inoculating.jsonl'\n",
    "\n",
    "train_file = '../resources/msgs/syntactic_category_relative_position/train.jsonl'\n",
    "test_file = '../resources/msgs/syntactic_category_relative_position/test.jsonl'\n",
    "inoc_file = '../resources/msgs/syntactic_category_relative_position/inoculating.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jsonl(filename):\n",
    "    with open(filename, 'r') as json_file:\n",
    "        json_list = list(json_file)\n",
    "    return_raw_data = []\n",
    "    for json_str in json_list:\n",
    "        result = json.loads(json_str)\n",
    "        return_raw_data.append(result)\n",
    "    return return_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = process_jsonl(train_file)\n",
    "raw_dev_test_data = process_jsonl(test_file)\n",
    "\n",
    "raw_dev_data = raw_dev_test_data[:int(len(raw_dev_test_data)/2)]\n",
    "raw_test_data = raw_dev_test_data[int(len(raw_dev_test_data)/2):]\n",
    "\n",
    "raw_inoc_data = process_jsonl(inoc_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'The dentist is singing some melody and every sick niece is in a cafe.',\n",
       " 'condition': 'training',\n",
       " 'linguistic_feature_label': 1,\n",
       " 'surface_feature_label': 1,\n",
       " 'UID': 'syntactic_category_relative_position',\n",
       " 'linguistic_feature_type': 'syntactic',\n",
       " 'linguistic_feature_description': 'Is there an adjective present?',\n",
       " 'surface_feature_type': 'relative_position',\n",
       " 'surface_feature_description': \"Does the word 'the' precede the word 'a'?\",\n",
       " 'control_paradigm': False,\n",
       " 'sentenceID': 40000,\n",
       " 'paradigmID': 5000,\n",
       " 'split': 'train'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(d['sentence'].split()) for d in raw_train_data]), max([len(d['sentence'].split()) for d in raw_dev_test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_dataset(raw_train_data, raw_inoc_data, inoc_rate, seed, if_full_train_set=False):\n",
    "    random.seed(seed)\n",
    "    train_data = []\n",
    "    buffer = []\n",
    "    for d in raw_train_data:\n",
    "        if if_full_train_set:\n",
    "            train_data.append((d['sentence'], d['linguistic_feature_label'], [d['linguistic_feature_label'], d['surface_feature_label']]))\n",
    "            continue\n",
    "        if len(buffer) < 2:\n",
    "            buffer.append(d)\n",
    "        if len(buffer) == 2:\n",
    "            _d = random.choice(buffer)\n",
    "            train_data.append((_d['sentence'], _d['linguistic_feature_label'], [_d['linguistic_feature_label'], _d['surface_feature_label']]))\n",
    "            buffer = []\n",
    "\n",
    "    random.seed(seed + 1)\n",
    "    inoc_data = []\n",
    "    buffer = []\n",
    "    for d in raw_inoc_data:\n",
    "        if if_full_train_set:\n",
    "            inoc_data.append((d['sentence'], d['linguistic_feature_label'], [d['linguistic_feature_label'], d['surface_feature_label']]))\n",
    "            continue\n",
    "        if len(buffer) < 2:\n",
    "            buffer.append(d)\n",
    "        if len(buffer) == 2:\n",
    "            _d = random.choice(buffer)\n",
    "            inoc_data.append((_d['sentence'], _d['linguistic_feature_label'], [_d['linguistic_feature_label'], _d['surface_feature_label']]))\n",
    "            buffer = []\n",
    "\n",
    "    num_inoc_ex = int(len(train_data) * inoc_rate)\n",
    "    train_data = train_data[:-num_inoc_ex] + inoc_data[-num_inoc_ex:]\n",
    "\n",
    "    random.shuffle(train_data)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_test_dataset(raw_data, seed):\n",
    "    random.seed(seed)\n",
    "    dataset = []\n",
    "    for d in raw_data:\n",
    "        dataset.append((d['sentence'], d['linguistic_feature_label'], [d['linguistic_feature_label'], d['surface_feature_label']]))\n",
    "    random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inoc_rate in [0.003, 0.01, 0.03]:\n",
    "    dir_name = f\"msgs_half_{inoc_rate}/\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    train_data = create_train_dataset(raw_train_data, raw_inoc_data, inoc_rate=inoc_rate, seed=2021)\n",
    "    dev_data = create_test_dataset(raw_dev_data, seed=2023) # 66.7% core-spur correlation in dev and test\n",
    "    test_data = create_test_dataset(raw_test_data, seed=2024)\n",
    "    pickle.dump(train_data, open(f\"{dir_name}msgs_train.pkl\", 'wb'))\n",
    "    pickle.dump(dev_data, open(f\"{dir_name}msgs_dev.pkl\", 'wb'))\n",
    "    pickle.dump(test_data, open(f\"{dir_name}msgs_test.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inoc_rate in [0.003, 0.01, 0.03]:\n",
    "    dir_name = f\"msgs_full_{inoc_rate}/\"\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    train_data = create_train_dataset(raw_train_data, raw_inoc_data, inoc_rate=inoc_rate, seed=2021, if_full_train_set=True)\n",
    "    dev_data = create_test_dataset(raw_dev_data, seed=2023) # 66.7% core-spur correlation in dev and test\n",
    "    test_data = create_test_dataset(raw_test_data, seed=2024)\n",
    "    pickle.dump(train_data, open(f\"{dir_name}msgs_train.pkl\", 'wb'))\n",
    "    pickle.dump(dev_data, open(f\"{dir_name}msgs_dev.pkl\", 'wb'))\n",
    "    pickle.dump(test_data, open(f\"{dir_name}msgs_test.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 15000 15000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(dev_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
